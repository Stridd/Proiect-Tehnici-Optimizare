# Proiect-Tehnici-Optimizare

Proiectul contine implementarea urmatorilor algoritmi de optimizare pentru o problema de clasificare in machine learning:
1. Gradient Descent
2. Stochastic Gradient Descent
3. Stochastic Gradient Descent with Momentum
4. Stochastic Gradient Descent with Nesterov Momentum
5. RMSProp
6. ADAM


Referinte:
  - Sebastian Ruder: http://ruder.io/optimizing-gradient-descent/
  - Cursul lui Andrew Ng: https://www.coursera.org/specializations/deep-learning
  - Wikipedia: https://en.wikipedia.org/wiki/Gradient_descent

